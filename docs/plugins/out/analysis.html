<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.12">
<title>OpenSearch Plugins and Integrations</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:50%;border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<style>.toc-current{font-weight: bold;} .toc-root{font-family: "Open Sans","DejaVu Sans",sans-serif;
                       font-size: 0.9em;} #content{display: flex; flex-direction: column; flex: 1 1 auto;}
             .nav-footer{text-align: center; margin-top: auto;}
             .nav-footer > p > a {white-space: nowrap;}</style>
</head>
<body id="analysis" class="book toc2 toc-left">
<div id="header">
<h1>OpenSearch Plugins and Integrations</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<p><span class="toc-root"><a href="index.html">OpenSearch Plugins and Integrations</a></span></p><ul class="sectlevel1">
<li><a href="intro.html">Introduction to plugins</a>
</li>
<li><a href="plugin-management.html">Plugin Management</a>
</li>
<li><a href="analysis.html"><span class="toc-current">Analysis Plugins</span></a>
<ul class="sectlevel2">
<li><a href="analysis.html#analysis-icu">ICU Analysis Plugin</a>
</li>
<li><a href="analysis.html#analysis-kuromoji">Japanese (kuromoji) Analysis Plugin</a>
</li>
<li><a href="analysis.html#analysis-nori">Korean (nori) Analysis Plugin</a>
</li>
<li><a href="analysis.html#analysis-phonetic">Phonetic Analysis Plugin</a>
</li>
<li><a href="analysis.html#analysis-smartcn">Smart Chinese Analysis Plugin</a>
</li>
<li><a href="analysis.html#analysis-stempel">Stempel Polish Analysis Plugin</a>
</li>
<li><a href="analysis.html#analysis-ukrainian">Ukrainian Analysis Plugin</a>
</li>
</ul>
</li>
<li><a href="discovery.html">Discovery Plugins</a>
</li>
<li><a href="ingest.html">Ingest Plugins</a>
</li>
<li><a href="mapper.html">Mapper Plugins</a>
</li>
<li><a href="repository.html">Snapshot/Restore Repository Plugins</a>
</li>
<li><a href="store.html">Store Plugins</a>
</li>
<li><a href="plugin-authors.html">Help for plugin authors</a>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="analysis">Analysis Plugins</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Analysis plugins extend OpenSearch by adding new analyzers, tokenizers,
token filters, or character filters.</p>
</div>
<h4 id="_core_analysis_plugins" class="discrete">Core analysis plugins</h4>
<div class="paragraph">
<p>The core analysis plugins are:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="analysis.html#analysis-icu">ICU</a></dt>
<dd>
<p>Adds extended Unicode support using the <a href="http://site.icu-project.org/">ICU</a>
libraries, including better analysis of Asian languages, Unicode
normalization, Unicode-aware case folding, collation support, and
transliteration.</p>
</dd>
<dt class="hdlist1"><a href="analysis.html#analysis-kuromoji">Kuromoji</a></dt>
<dd>
<p>Advanced analysis of Japanese using the <a href="https://www.atilika.org/">Kuromoji analyzer</a>.</p>
</dd>
<dt class="hdlist1"><a href="analysis.html#analysis-nori">Nori</a></dt>
<dd>
<p>Morphological analysis of Korean using the Lucene Nori analyzer.</p>
</dd>
<dt class="hdlist1"><a href="analysis.html#analysis-phonetic">Phonetic</a></dt>
<dd>
<p>Analyzes tokens into their phonetic equivalent using Soundex, Metaphone,
Caverphone, and other codecs.</p>
</dd>
<dt class="hdlist1"><a href="analysis.html#analysis-smartcn">SmartCN</a></dt>
<dd>
<p>An analyzer for Chinese or mixed Chinese-English text. This analyzer uses
probabilistic knowledge to find the optimal word segmentation for Simplified
Chinese text. The text is first broken into sentences, then each sentence is
segmented into words.</p>
</dd>
<dt class="hdlist1"><a href="analysis.html#analysis-stempel">Stempel</a></dt>
<dd>
<p>Provides high quality stemming for Polish.</p>
</dd>
<dt class="hdlist1"><a href="analysis.html#analysis-ukrainian">Ukrainian</a></dt>
<dd>
<p>Provides stemming for Ukrainian.</p>
</dd>
</dl>
</div>
<div class="sect2">
<h3 id="analysis-icu">ICU Analysis Plugin</h3>
<div class="paragraph">
<p>The ICU Analysis plugin integrates the Lucene ICU module into OpenSearch,
adding extended Unicode support using the <a href="http://site.icu-project.org/">ICU</a>
libraries, including better analysis of Asian languages, Unicode
normalization, Unicode-aware case folding, collation support, and
transliteration.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="title">ICU analysis and backwards compatibility</div>
<div class="paragraph">
<p>From time to time, the ICU library receives updates such as adding new
characters and emojis, and improving collation (sort) orders.  These changes
may or may not affect search and sort orders, depending on which characters
sets you are using.</p>
</div>
<div class="paragraph">
<p>While we restrict ICU upgrades to major versions, you may find that an index
created in the previous major version will need to be reindexed in order to
return correct (and correctly ordered) results, and to take advantage of new
characters.</p>
</div>
</td>
</tr>
</table>
</div>
<h4 id="analysis-icu-install" class="discrete">Installation</h4>
<div class="paragraph">
<p>This plugin can be installed using the plugin manager:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin install analysis-icu</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.</p>
</div>
<div class="paragraph">
<p>You can download this plugin for <a href="plugin-management.html#plugin-management-custom-url">offline
install</a> from <a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-icu/analysis-icu-1.0.0.zip" class="bare">https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-icu/analysis-icu-1.0.0.zip</a>. To verify
the <code>.zip</code> file, use the
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-icu/analysis-icu-1.0.0.zip.sha512">SHA hash</a> or
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-icu/analysis-icu-1.0.0.zip.asc">ASC key</a>.</p>
</div>
<h4 id="analysis-icu-remove" class="discrete">Removal</h4>
<div class="paragraph">
<p>The plugin can be removed with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin remove analysis-icu</code></pre>
</div>
</div>
<div class="paragraph">
<p>The node must be stopped before removing the plugin.</p>
</div>
<div class="sect3">
<h4 id="analysis-icu-analyzer">ICU Analyzer</h4>
<div class="paragraph">
<p>The <code>icu_analyzer</code> analyzer performs basic normalization, tokenization and character folding, using the
<code>icu_normalizer</code> char filter, <code>icu_tokenizer</code> and <code>icu_folding</code> token filter</p>
</div>
<div class="paragraph">
<p>The following parameters are accepted:</p>
</div>
<div class="hdlist">
<table>
<tr>
<td class="hdlist1">
<code>method</code>
</td>
<td class="hdlist2">
<p>Normalization method.  Accepts <code>nfkc</code>, <code>nfc</code> or <code>nfkc_cf</code> (default)</p>
</td>
</tr>
<tr>
<td class="hdlist1">
<code>mode</code>
</td>
<td class="hdlist2">
<p>Normalization mode.  Accepts <code>compose</code> (default) or <code>decompose</code>.</p>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="analysis-icu-normalization-charfilter">ICU Normalization Character Filter</h4>
<div class="paragraph">
<p>Normalizes characters as explained
<a href="http://userguide.icu-project.org/transforms/normalization">here</a>.
It registers itself as the <code>icu_normalizer</code> character filter, which is
available to all indices without any further configuration. The type of
normalization can be specified with the <code>name</code> parameter, which accepts <code>nfc</code>,
<code>nfkc</code>, and <code>nfkc_cf</code> (default).  Set the <code>mode</code> parameter to <code>decompose</code> to
convert <code>nfc</code> to <code>nfd</code> or <code>nfkc</code> to <code>nfkd</code> respectively:</p>
</div>
<div class="paragraph">
<p>Which letters are normalized can be controlled by specifying the
<code>unicode_set_filter</code> parameter, which accepts a
<a href="https://icu-project.org/apiref/icu4j/com/ibm/icu/text/UnicodeSet.html">UnicodeSet</a>.</p>
</div>
<div class="paragraph">
<p>Here are two examples, the default usage and a customised character filter:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "nfkc_cf_normalized": { <b class="conum">(1)</b>
            "tokenizer": "icu_tokenizer",
            "char_filter": [
              "icu_normalizer"
            ]
          },
          "nfd_normalized": { <b class="conum">(2)</b>
            "tokenizer": "icu_tokenizer",
            "char_filter": [
              "nfd_normalizer"
            ]
          }
        },
        "char_filter": {
          "nfd_normalizer": {
            "type": "icu_normalizer",
            "name": "nfc",
            "mode": "decompose"
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Uses the default <code>nfkc_cf</code> normalization.</p>
</li>
<li>
<p>Uses the customized <code>nfd_normalizer</code> token filter, which is set to use <code>nfc</code> normalization with decomposition.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="analysis-icu-tokenizer">ICU Tokenizer</h4>
<div class="paragraph">
<p>Tokenizes text into words on word boundaries, as defined in
<a href="https://www.unicode.org/reports/tr29/">UAX #29: Unicode Text Segmentation</a>.
It behaves much like the <a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-standard-tokenizer.html"><code>standard</code> tokenizer</a>,
but adds better support for some Asian languages by using a dictionary-based
approach to identify words in Thai, Lao, Chinese, Japanese, and Korean, and
using custom rules to break Myanmar and Khmer text into syllables.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_icu_analyzer": {
            "tokenizer": "icu_tokenizer"
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_rules_customization">Rules customization</h5>
<div class="paragraph">
<p>experimental[This functionality is marked as experimental in Lucene]</p>
</div>
<div class="paragraph">
<p>You can customize the <code>icu-tokenizer</code> behavior by specifying per-script rule files, see the
<a href="http://userguide.icu-project.org/boundaryanalysis#TOC-RBBI-Rules">RBBI rules syntax reference</a>
for a more detailed explanation.</p>
</div>
<div class="paragraph">
<p>To add icu tokenizer rules, set the <code>rule_files</code> settings, which should contain a comma-separated list of
<code>code:rulefile</code> pairs in the following format:
<a href="https://unicode.org/iso15924/iso15924-codes.html">four-letter ISO 15924 script code</a>,
followed by a colon, then a rule file name. Rule files are placed <code>OPENSEARCH_HOME/config</code> directory.</p>
</div>
<div class="paragraph">
<p>As a demonstration of how the rule files can be used, save the following user file to <code>$OPENSEARCH_HOME/config/KeywordTokenizer.rbbi</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-text" data-lang="text">.+ {200};</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then create an analyzer to use this rule file as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "icu_user_file": {
            "type": "icu_tokenizer",
            "rule_files": "Latn:KeywordTokenizer.rbbi"
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "icu_user_file"
          }
        }
      }
    }
  }
}

GET icu_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "OpenSearch. Wow!"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above <code>analyze</code> request returns the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
   "tokens": [
      {
         "token": "OpenSearch. Wow!",
         "start_offset": 0,
         "end_offset": 16,
         "type": "&lt;ALPHANUM&gt;",
         "position": 0
      }
   ]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-icu-normalization">ICU Normalization Token Filter</h4>
<div class="paragraph">
<p>Normalizes characters as explained
<a href="http://userguide.icu-project.org/transforms/normalization">here</a>. It registers
itself as the <code>icu_normalizer</code> token filter, which is available to all indices
without any further configuration. The type of normalization can be specified
with the <code>name</code> parameter, which accepts <code>nfc</code>, <code>nfkc</code>, and <code>nfkc_cf</code>
(default).</p>
</div>
<div class="paragraph">
<p>Which letters are normalized can be controlled by specifying the
<code>unicode_set_filter</code> parameter, which accepts a
<a href="https://icu-project.org/apiref/icu4j/com/ibm/icu/text/UnicodeSet.html">UnicodeSet</a>.</p>
</div>
<div class="paragraph">
<p>You should probably prefer the <a href="analysis.html#analysis-icu-normalization-charfilter">Normalization character filter</a>.</p>
</div>
<div class="paragraph">
<p>Here are two examples, the default usage and a customised token filter:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "nfkc_cf_normalized": { <b class="conum">(1)</b>
            "tokenizer": "icu_tokenizer",
            "filter": [
              "icu_normalizer"
            ]
          },
          "nfc_normalized": { <b class="conum">(2)</b>
            "tokenizer": "icu_tokenizer",
            "filter": [
              "nfc_normalizer"
            ]
          }
        },
        "filter": {
          "nfc_normalizer": {
            "type": "icu_normalizer",
            "name": "nfc"
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Uses the default <code>nfkc_cf</code> normalization.</p>
</li>
<li>
<p>Uses the customized <code>nfc_normalizer</code> token filter, which is set to use <code>nfc</code> normalization.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="analysis-icu-folding">ICU Folding Token Filter</h4>
<div class="paragraph">
<p>Case folding of Unicode characters based on <code>UTR#30</code>, like the
<a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-asciifolding-tokenfilter.html">ASCII-folding token filter</a>
on steroids. It registers itself as the <code>icu_folding</code> token filter and is
available to all indices:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "folded": {
            "tokenizer": "icu_tokenizer",
            "filter": [
              "icu_folding"
            ]
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The ICU folding token filter already does Unicode normalization, so there is
no need to use Normalize character or token filter as well.</p>
</div>
<div class="paragraph">
<p>Which letters are folded can be controlled by specifying the
<code>unicode_set_filter</code> parameter, which accepts a
<a href="https://icu-project.org/apiref/icu4j/com/ibm/icu/text/UnicodeSet.html">UnicodeSet</a>.</p>
</div>
<div class="paragraph">
<p>The following example exempts Swedish characters from folding. It is important
to note that both upper and lowercase forms should be specified, and that
these filtered character are not lowercased which is why we add the
<code>lowercase</code> filter as well:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "swedish_analyzer": {
            "tokenizer": "icu_tokenizer",
            "filter": [
              "swedish_folding",
              "lowercase"
            ]
          }
        },
        "filter": {
          "swedish_folding": {
            "type": "icu_folding",
            "unicode_set_filter": "[^åäöÅÄÖ]"
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-icu-collation">ICU Collation Token Filter</h4>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
<div class="paragraph">
<p>This token filter has been deprecated since Lucene 5.0.  Please use
<a href="analysis.html#analysis-icu-collation-keyword-field">ICU Collation Keyword Field</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="analysis-icu-collation-keyword-field">ICU Collation Keyword Field</h4>
<div class="paragraph">
<p>Collations are used for sorting documents in a language-specific word order.
The <code>icu_collation_keyword</code> field type is available to all indices and will encode
the terms directly as bytes in a doc values field and a single indexed token just
like a standard <a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/keyword.html">Keyword Field</a>.</p>
</div>
<div class="paragraph">
<p>Defaults to using <a href="https://www.opensearch.org/guide/en/opensearch/guide/2.x/sorting-collations.html#uca">DUCET collation</a>,
which is a best-effort attempt at language-neutral sorting.</p>
</div>
<div class="paragraph">
<p>Below is an example of how to set up a field for sorting German names in
``phonebook'' order:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT my-index-000001
{
  "mappings": {
    "properties": {
      "name": {   <b class="conum">(1)</b>
        "type": "text",
        "fields": {
          "sort": {  <b class="conum">(2)</b>
            "type": "icu_collation_keyword",
            "index": false,
            "language": "de",
            "country": "DE",
            "variant": "@collation=phonebook"
          }
        }
      }
    }
  }
}

GET /my-index-000001/_search <b class="conum">(3)</b>
{
  "query": {
    "match": {
      "name": "Fritz"
    }
  },
  "sort": "name.sort"
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>The <code>name</code> field uses the <code>standard</code> analyzer, and so support full text queries.</p>
</li>
<li>
<p>The <code>name.sort</code> field is an <code>icu_collation_keyword</code> field that will preserve the name as
a single token doc values, and applies the German ``phonebook'' order.</p>
</li>
<li>
<p>An example query which searches the <code>name</code> field and sorts on the <code>name.sort</code> field.</p>
</li>
</ol>
</div>
<div class="sect4">
<h5 id="_parameters_for_icu_collation_keyword_fields">Parameters for ICU Collation Keyword Fields</h5>
<div class="paragraph">
<p>The following parameters are accepted by <code>icu_collation_keyword</code> fields:</p>
</div>
<div class="hdlist">
<table>
<tr>
<td class="hdlist1">
<code>doc_values</code>
</td>
<td class="hdlist2">
<p>Should the field be stored on disk in a column-stride fashion, so that it
can later be used for sorting, aggregations, or scripting? Accepts <code>true</code>
(default) or <code>false</code>.</p>
</td>
</tr>
<tr>
<td class="hdlist1">
<code>index</code>
</td>
<td class="hdlist2">
<p>Should the field be searchable? Accepts <code>true</code> (default) or <code>false</code>.</p>
</td>
</tr>
<tr>
<td class="hdlist1">
<code>null_value</code>
</td>
<td class="hdlist2">
<p>Accepts a string value which is substituted for any explicit <code>null</code>
values.  Defaults to <code>null</code>, which means the field is treated as missing.</p>
</td>
</tr>
<tr>
<td class="hdlist1">
<a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/ignore-above.html"><code>ignore_above</code></a>
</td>
<td class="hdlist2">
<p>Strings longer than the <code>ignore_above</code> setting will be ignored.
Checking is performed on the original string before the collation.
The <code>ignore_above</code> setting can be updated on existing fields
using the <a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/indices-put-mapping.html">PUT mapping API</a>.
By default, there is no limit and all values will be indexed.</p>
</td>
</tr>
<tr>
<td class="hdlist1">
<code>store</code>
</td>
<td class="hdlist2">
<p>Whether the field value should be stored and retrievable separately from
the <a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/mapping-source-field.html"><code>_source</code></a> field. Accepts <code>true</code> or <code>false</code>
(default).</p>
</td>
</tr>
<tr>
<td class="hdlist1">
<code>fields</code>
</td>
<td class="hdlist2">
<p>Multi-fields allow the same string value to be indexed in multiple ways for
different purposes, such as one field for search and a multi-field for
sorting and aggregations.</p>
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_collation_options">Collation options</h5>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>strength</code></dt>
<dd>
<p>The strength property determines the minimum level of difference considered
significant during comparison. Possible values are : <code>primary</code>, <code>secondary</code>,
<code>tertiary</code>, <code>quaternary</code> or <code>identical</code>. See the
<a href="https://icu-project.org/apiref/icu4j/com/ibm/icu/text/Collator.html">ICU Collation documentation</a>
for a more detailed  explanation for each value.  Defaults to <code>tertiary</code>
unless otherwise specified in the collation.</p>
</dd>
<dt class="hdlist1"><code>decomposition</code></dt>
<dd>
<p>Possible values: <code>no</code> (default, but collation-dependent) or <code>canonical</code>.
Setting this decomposition property to <code>canonical</code> allows the Collator to
handle unnormalized text properly, producing the same results as if the text
were normalized. If <code>no</code> is set, it is the user&#8217;s responsibility to insure
that all text is already in the appropriate form before a comparison or before
getting a CollationKey. Adjusting decomposition mode allows the user to select
between faster and more complete collation behavior. Since a great many of the
world&#8217;s languages do not require text normalization, most locales set <code>no</code> as
the default decomposition mode.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The following options are expert only:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>alternate</code></dt>
<dd>
<p>Possible values: <code>shifted</code> or <code>non-ignorable</code>. Sets the alternate handling for
strength <code>quaternary</code> to be either shifted or non-ignorable. Which boils down
to ignoring punctuation and whitespace.</p>
</dd>
<dt class="hdlist1"><code>case_level</code></dt>
<dd>
<p>Possible values: <code>true</code> or <code>false</code> (default). Whether case level sorting is
required. When strength is set to <code>primary</code> this will ignore accent
differences.</p>
</dd>
<dt class="hdlist1"><code>case_first</code></dt>
<dd>
<p>Possible values: <code>lower</code> or <code>upper</code>. Useful to control which case is sorted
first when case is not ignored for strength <code>tertiary</code>. The default depends on
the collation.</p>
</dd>
<dt class="hdlist1"><code>numeric</code></dt>
<dd>
<p>Possible values: <code>true</code> or <code>false</code> (default) . Whether digits are sorted
according to their numeric representation. For example the value <code>egg-9</code> is
sorted before the value <code>egg-21</code>.</p>
</dd>
<dt class="hdlist1"><code>variable_top</code></dt>
<dd>
<p>Single character or contraction. Controls what is variable for <code>alternate</code>.</p>
</dd>
<dt class="hdlist1"><code>hiragana_quaternary_mode</code></dt>
<dd>
<p>Possible values: <code>true</code> or <code>false</code>.  Distinguishing between Katakana and
Hiragana characters in <code>quaternary</code> strength.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-icu-transform">ICU Transform Token Filter</h4>
<div class="paragraph">
<p>Transforms are used to process Unicode text in many different ways, such as
case mapping, normalization, transliteration and bidirectional text handling.</p>
</div>
<div class="paragraph">
<p>You can define which transformation you want to apply with the <code>id</code> parameter
(defaults to <code>Null</code>), and specify text direction with the <code>dir</code> parameter
which accepts <code>forward</code> (default) for LTR and <code>reverse</code> for RTL.  Custom
rulesets are not yet supported.</p>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "latin": {
            "tokenizer": "keyword",
            "filter": [
              "myLatinTransform"
            ]
          }
        },
        "filter": {
          "myLatinTransform": {
            "type": "icu_transform",
            "id": "Any-Latin; NFD; [:Nonspacing Mark:] Remove; NFC" <b class="conum">(1)</b>
          }
        }
      }
    }
  }
}

GET icu_sample/_analyze
{
  "analyzer": "latin",
  "text": "你好" <b class="conum">(2)</b>
}

GET icu_sample/_analyze
{
  "analyzer": "latin",
  "text": "здравствуйте" <b class="conum">(3)</b>
}

GET icu_sample/_analyze
{
  "analyzer": "latin",
  "text": "こんにちは" <b class="conum">(4)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>This transforms transliterates characters to Latin, and separates accents
from their base characters, removes the accents, and then puts the
remaining text into an unaccented form.</p>
</li>
<li>
<p>Returns <code>ni hao</code>.</p>
</li>
<li>
<p>Returns <code>zdravstvujte</code>.</p>
</li>
<li>
<p>Returns <code>kon&#8217;nichiha</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For more documentation, Please see the <a href="http://userguide.icu-project.org/transforms/general">user guide of ICU Transform</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="analysis-kuromoji">Japanese (kuromoji) Analysis Plugin</h3>
<div class="paragraph">
<p>The Japanese (kuromoji) Analysis plugin integrates Lucene kuromoji analysis
module into OpenSearch.</p>
</div>
<h4 id="analysis-kuromoji-install" class="discrete">Installation</h4>
<div class="paragraph">
<p>This plugin can be installed using the plugin manager:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin install analysis-kuromoji</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.</p>
</div>
<div class="paragraph">
<p>You can download this plugin for <a href="plugin-management.html#plugin-management-custom-url">offline
install</a> from <a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-kuromoji/analysis-kuromoji-1.0.0.zip" class="bare">https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-kuromoji/analysis-kuromoji-1.0.0.zip</a>. To verify
the <code>.zip</code> file, use the
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-kuromoji/analysis-kuromoji-1.0.0.zip.sha512">SHA hash</a> or
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-kuromoji/analysis-kuromoji-1.0.0.zip.asc">ASC key</a>.</p>
</div>
<h4 id="analysis-kuromoji-remove" class="discrete">Removal</h4>
<div class="paragraph">
<p>The plugin can be removed with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin remove analysis-kuromoji</code></pre>
</div>
</div>
<div class="paragraph">
<p>The node must be stopped before removing the plugin.</p>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-analyzer"><code>kuromoji</code> analyzer</h4>
<div class="paragraph">
<p>The <code>kuromoji</code> analyzer consists of the following tokenizer and token filters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="analysis.html#analysis-kuromoji-tokenizer"><code>kuromoji_tokenizer</code></a></p>
</li>
<li>
<p><a href="analysis.html#analysis-kuromoji-baseform"><code>kuromoji_baseform</code></a> token filter</p>
</li>
<li>
<p><a href="analysis.html#analysis-kuromoji-speech"><code>kuromoji_part_of_speech</code></a> token filter</p>
</li>
<li>
<p><a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-cjk-width-tokenfilter.html"><code>cjk_width</code></a> token filter</p>
</li>
<li>
<p><a href="analysis.html#analysis-kuromoji-stop"><code>ja_stop</code></a> token filter</p>
</li>
<li>
<p><a href="analysis.html#analysis-kuromoji-stemmer"><code>kuromoji_stemmer</code></a> token filter</p>
</li>
<li>
<p><a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-lowercase-tokenfilter.html"><code>lowercase</code></a> token filter</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It supports the <code>mode</code> and <code>user_dictionary</code> settings from
<a href="analysis.html#analysis-kuromoji-tokenizer"><code>kuromoji_tokenizer</code></a>.</p>
</div>
<h4 id="kuromoji-analyzer-normalize-full-width-characters" class="discrete">Normalize full-width characters</h4>
<div class="paragraph">
<p>The <code>kuromoji_tokenizer</code> tokenizer uses characters from the MeCab-IPADIC
dictionary to split text into tokens. The dictionary includes some full-width
characters, such as <code>ｏ</code> and <code>ｆ</code>. If a text contains full-width characters,
the tokenizer can produce unexpected tokens.</p>
</div>
<div class="paragraph">
<p>For example, the <code>kuromoji_tokenizer</code> tokenizer converts the text
<code>Ｃｕｌｔｕｒｅ　ｏｆ　Ｊａｐａｎ</code> to the tokens <code>[ culture, o, f, japan ]</code>
instead of <code>[ culture, of, japan ]</code>.</p>
</div>
<div class="paragraph">
<p>To avoid this, add the <a href="analysis.html#analysis-icu-normalization-charfilter"><code>icu_normalizer</code>
character filter</a> to a custom analyzer based on the <code>kuromoji</code> analyzer. The
<code>icu_normalizer</code> character filter converts full-width characters to their normal
equivalents.</p>
</div>
<div class="paragraph">
<p>First, duplicate the <code>kuromoji</code> analyzer to create the basis for a custom
analyzer. Then add the <code>icu_normalizer</code> character filter to the custom analyzer.
For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT index-00001
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "kuromoji_normalize": {                 <b class="conum">(1)</b>
            "char_filter": [
              "icu_normalizer"                    <b class="conum">(2)</b>
            ],
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "kuromoji_baseform",
              "kuromoji_part_of_speech",
              "cjk_width",
              "ja_stop",
              "kuromoji_stemmer",
              "lowercase"
            ]
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Creates a new custom analyzer, <code>kuromoji_normalize</code>, based on the <code>kuromoji</code>
analyzer.</p>
</li>
<li>
<p>Adds the <code>icu_normalizer</code> character filter to the analyzer.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-charfilter"><code>kuromoji_iteration_mark</code> character filter</h4>
<div class="paragraph">
<p>The <code>kuromoji_iteration_mark</code> normalizes Japanese horizontal iteration marks
(<em>odoriji</em>) to their expanded form. It accepts the following settings:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>normalize_kanji</code></dt>
<dd>
<p>Indicates whether kanji iteration marks should be normalize. Defaults to <code>true</code>.</p>
</dd>
<dt class="hdlist1"><code>normalize_kana</code></dt>
<dd>
<p>Indicates whether kana iteration marks should be normalized. Defaults to <code>true</code></p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-tokenizer"><code>kuromoji_tokenizer</code></h4>
<div class="paragraph">
<p>The <code>kuromoji_tokenizer</code> accepts the following settings:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>mode</code></dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>The tokenization mode determines how the tokenizer handles compound and
unknown words.  It can be set to:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>normal</code></dt>
<dd>
<p>Normal segmentation, no decomposition for compounds. Example output:</p>
<div class="literalblock">
<div class="content">
<pre>関西国際空港
アブラカダブラ</pre>
</div>
</div>
</dd>
<dt class="hdlist1"><code>search</code></dt>
<dd>
<p>Segmentation geared towards search. This includes a decompounding process
for long nouns, also including the full compound token as a synonym.
Example output:</p>
<div class="literalblock">
<div class="content">
<pre>関西, 関西国際空港, 国際, 空港
アブラカダブラ</pre>
</div>
</div>
</dd>
<dt class="hdlist1"><code>extended</code></dt>
<dd>
<p>Extended mode outputs unigrams for unknown words. Example output:</p>
<div class="literalblock">
<div class="content">
<pre>関西, 関西国際空港, 国際, 空港
ア, ブ, ラ, カ, ダ, ブ, ラ</pre>
</div>
</div>
</dd>
</dl>
</div>
</div>
</div>
</dd>
<dt class="hdlist1"><code>discard_punctuation</code></dt>
<dd>
<p>Whether punctuation should be discarded from the output. Defaults to <code>true</code>.</p>
</dd>
<dt class="hdlist1"><code>user_dictionary</code></dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>The Kuromoji tokenizer uses the MeCab-IPADIC dictionary by default. A <code>user_dictionary</code>
may be appended to the default dictionary. The dictionary should have the following CSV format:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-csv" data-lang="csv">&lt;text&gt;,&lt;token 1&gt; ... &lt;token n&gt;,&lt;reading 1&gt; ... &lt;reading n&gt;,&lt;part-of-speech tag&gt;</code></pre>
</div>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>As a demonstration of how the user dictionary can be used, save the following
dictionary to <code>$OPENSEARCH_HOME/config/userdict_ja.txt</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-csv" data-lang="csv">東京スカイツリー,東京 スカイツリー,トウキョウ スカイツリー,カスタム名詞</code></pre>
</div>
</div>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>You can also inline the rules directly in the tokenizer definition using
the <code>user_dictionary_rules</code> option:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "kuromoji_user_dict": {
            "type": "kuromoji_tokenizer",
            "mode": "extended",
            "user_dictionary_rules": ["東京スカイツリー,東京 スカイツリー,トウキョウ スカイツリー,カスタム名詞"]
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "kuromoji_user_dict"
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>nbest_cost</code>/<code>nbest_examples</code></dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>Additional expert user parameters <code>nbest_cost</code> and <code>nbest_examples</code> can be used
to include additional tokens that most likely according to the statistical model.
If both parameters are used, the largest number of both is applied.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>nbest_cost</code></dt>
<dd>
<p>The <code>nbest_cost</code> parameter specifies an additional Viterbi cost.
The KuromojiTokenizer will include all tokens in Viterbi paths that are
within the nbest_cost value of the best path.</p>
</dd>
<dt class="hdlist1"><code>nbest_examples</code></dt>
<dd>
<p>The <code>nbest_examples</code> can be used to find a <code>nbest_cost</code> value based on examples.
For example, a value of /箱根山-箱根/成田空港-成田/ indicates that in the texts,
箱根山 (Mt. Hakone) and 成田空港 (Narita Airport) we&#8217;d like a cost that gives is us
箱根 (Hakone) and 成田 (Narita).</p>
</dd>
</dl>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Then create an analyzer as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "kuromoji_user_dict": {
            "type": "kuromoji_tokenizer",
            "mode": "extended",
            "discard_punctuation": "false",
            "user_dictionary": "userdict_ja.txt"
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "kuromoji_user_dict"
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "東京スカイツリー"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above <code>analyze</code> request returns the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "東京",
    "start_offset" : 0,
    "end_offset" : 2,
    "type" : "word",
    "position" : 0
  }, {
    "token" : "スカイツリー",
    "start_offset" : 2,
    "end_offset" : 8,
    "type" : "word",
    "position" : 1
  } ]
}</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>discard_compound_token</code></dt>
<dd>
<p>Whether original compound tokens should be discarded from the output with <code>search</code> mode. Defaults to <code>false</code>.
Example output with <code>search</code> or <code>extended</code> mode and this option <code>true</code>:</p>
<div class="literalblock">
<div class="content">
<pre>関西, 国際, 空港</pre>
</div>
</div>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
If a text contains full-width characters, the <code>kuromoji_tokenizer</code>
tokenizer can produce unexpected tokens. To avoid this, add the
<a href="analysis.html#analysis-icu-normalization-charfilter"><code>icu_normalizer</code> character filter</a> to
your analyzer. See <a href="analysis.html#kuromoji-analyzer-normalize-full-width-characters">Normalize full-width characters</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-baseform"><code>kuromoji_baseform</code> token filter</h4>
<div class="paragraph">
<p>The <code>kuromoji_baseform</code> token filter replaces terms with their
BaseFormAttribute. This acts as a lemmatizer for verbs and adjectives. Example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "kuromoji_baseform"
            ]
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "飲み"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>which responds with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "飲む",
    "start_offset" : 0,
    "end_offset" : 2,
    "type" : "word",
    "position" : 0
  } ]
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-speech"><code>kuromoji_part_of_speech</code> token filter</h4>
<div class="paragraph">
<p>The <code>kuromoji_part_of_speech</code> token filter removes tokens that match a set of
part-of-speech tags. It accepts the following setting:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>stoptags</code></dt>
<dd>
<p>An array of part-of-speech tags that should be removed. It defaults to the
<code>stoptags.txt</code> file embedded in the <code>lucene-analyzer-kuromoji.jar</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "my_posfilter"
            ]
          }
        },
        "filter": {
          "my_posfilter": {
            "type": "kuromoji_part_of_speech",
            "stoptags": [
              "助詞-格助詞-一般",
              "助詞-終助詞"
            ]
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "寿司がおいしいね"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which responds with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "寿司",
    "start_offset" : 0,
    "end_offset" : 2,
    "type" : "word",
    "position" : 0
  }, {
    "token" : "おいしい",
    "start_offset" : 3,
    "end_offset" : 7,
    "type" : "word",
    "position" : 2
  } ]
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-readingform"><code>kuromoji_readingform</code> token filter</h4>
<div class="paragraph">
<p>The <code>kuromoji_readingform</code> token filter replaces the token with its reading
form in either katakana or romaji. It accepts the following setting:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>use_romaji</code></dt>
<dd>
<p>Whether romaji reading form should be output instead of katakana.  Defaults to <code>false</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>When using the pre-defined <code>kuromoji_readingform</code> filter, <code>use_romaji</code> is set
to <code>true</code>. The default when defining a custom <code>kuromoji_readingform</code>, however,
is <code>false</code>.  The only reason to use the custom form is if you need the
katakana reading form:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "romaji_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [ "romaji_readingform" ]
          },
          "katakana_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [ "katakana_readingform" ]
          }
        },
        "filter": {
          "romaji_readingform": {
            "type": "kuromoji_readingform",
            "use_romaji": true
          },
          "katakana_readingform": {
            "type": "kuromoji_readingform",
            "use_romaji": false
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "katakana_analyzer",
  "text": "寿司" <b class="conum">(1)</b>
}

GET kuromoji_sample/_analyze
{
  "analyzer": "romaji_analyzer",
  "text": "寿司" <b class="conum">(2)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Returns <code>スシ</code>.</p>
</li>
<li>
<p>Returns <code>sushi</code>.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-stemmer"><code>kuromoji_stemmer</code> token filter</h4>
<div class="paragraph">
<p>The <code>kuromoji_stemmer</code> token filter normalizes common katakana spelling
variations ending in a long sound character by removing this character
(U+30FC). Only full-width katakana characters are supported.</p>
</div>
<div class="paragraph">
<p>This token filter accepts the following setting:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>minimum_length</code></dt>
<dd>
<p>Katakana words shorter than the <code>minimum length</code> are not stemmed (default
is <code>4</code>).</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "my_katakana_stemmer"
            ]
          }
        },
        "filter": {
          "my_katakana_stemmer": {
            "type": "kuromoji_stemmer",
            "minimum_length": 4
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "コピー" <b class="conum">(1)</b>
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "サーバー" <b class="conum">(2)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Returns <code>コピー</code>.</p>
</li>
<li>
<p>Return <code>サーバ</code>.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-stop"><code>ja_stop</code> token filter</h4>
<div class="paragraph">
<p>The <code>ja_stop</code> token filter filters out Japanese stopwords (<code><em>japanese</em></code>), and
any other custom stopwords specified by the user. This filter only supports
the predefined <code><em>japanese</em></code> stopwords list.  If you want to use a different
predefined list, then use the
<a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-stop-tokenfilter.html"><code>stop</code> token filter</a> instead.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "analyzer_with_ja_stop": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "ja_stop"
            ]
          }
        },
        "filter": {
          "ja_stop": {
            "type": "ja_stop",
            "stopwords": [
              "_japanese_",
              "ストップ"
            ]
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "analyzer_with_ja_stop",
  "text": "ストップは消える"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above request returns:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "消える",
    "start_offset" : 5,
    "end_offset" : 8,
    "type" : "word",
    "position" : 2
  } ]
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-kuromoji-number"><code>kuromoji_number</code> token filter</h4>
<div class="paragraph">
<p>The <code>kuromoji_number</code> token filter normalizes Japanese numbers (kansūji)
to regular Arabic decimal numbers in half-width characters. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT kuromoji_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "kuromoji_tokenizer",
            "filter": [
              "kuromoji_number"
            ]
          }
        }
      }
    }
  }
}

GET kuromoji_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "一〇〇〇"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which results in:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "1000",
    "start_offset" : 0,
    "end_offset" : 4,
    "type" : "word",
    "position" : 0
  } ]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="analysis-nori">Korean (nori) Analysis Plugin</h3>
<div class="paragraph">
<p>The Korean (nori) Analysis plugin integrates Lucene nori analysis
module into opensearch. It uses the <a href="https://bitbucket.org/eunjeon/mecab-ko-dic">mecab-ko-dic dictionary</a>
to perform morphological analysis of Korean texts.</p>
</div>
<h4 id="analysis-nori-install" class="discrete">Installation</h4>
<div class="paragraph">
<p>This plugin can be installed using the plugin manager:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin install analysis-nori</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.</p>
</div>
<div class="paragraph">
<p>You can download this plugin for <a href="plugin-management.html#plugin-management-custom-url">offline
install</a> from <a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-nori/analysis-nori-1.0.0.zip" class="bare">https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-nori/analysis-nori-1.0.0.zip</a>. To verify
the <code>.zip</code> file, use the
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-nori/analysis-nori-1.0.0.zip.sha512">SHA hash</a> or
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-nori/analysis-nori-1.0.0.zip.asc">ASC key</a>.</p>
</div>
<h4 id="analysis-nori-remove" class="discrete">Removal</h4>
<div class="paragraph">
<p>The plugin can be removed with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin remove analysis-nori</code></pre>
</div>
</div>
<div class="paragraph">
<p>The node must be stopped before removing the plugin.</p>
</div>
<div class="sect3">
<h4 id="analysis-nori-analyzer"><code>nori</code> analyzer</h4>
<div class="paragraph">
<p>The <code>nori</code> analyzer consists of the following tokenizer and token filters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="analysis.html#analysis-nori-tokenizer"><code>nori_tokenizer</code></a></p>
</li>
<li>
<p><a href="analysis.html#analysis-nori-speech"><code>nori_part_of_speech</code></a> token filter</p>
</li>
<li>
<p><a href="analysis.html#analysis-nori-readingform"><code>nori_readingform</code></a> token filter</p>
</li>
<li>
<p><a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-lowercase-tokenfilter.html"><code>lowercase</code></a> token filter</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It supports the <code>decompound_mode</code> and <code>user_dictionary</code> settings from
<a href="analysis.html#analysis-nori-tokenizer"><code>nori_tokenizer</code></a> and the <code>stoptags</code> setting from
<a href="analysis.html#analysis-nori-speech"><code>nori_part_of_speech</code></a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="analysis-nori-tokenizer"><code>nori_tokenizer</code></h4>
<div class="paragraph">
<p>The <code>nori_tokenizer</code> accepts the following settings:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>decompound_mode</code></dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>The decompound mode determines how the tokenizer handles compound tokens.
It can be set to:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>none</code></dt>
<dd>
<p>No decomposition for compounds. Example output:</p>
<div class="literalblock">
<div class="content">
<pre>가거도항
가곡역</pre>
</div>
</div>
</dd>
<dt class="hdlist1"><code>discard</code></dt>
<dd>
<p>Decomposes compounds and discards the original form (<strong>default</strong>). Example output:</p>
<div class="literalblock">
<div class="content">
<pre>가곡역 =&gt; 가곡, 역</pre>
</div>
</div>
</dd>
<dt class="hdlist1"><code>mixed</code></dt>
<dd>
<p>Decomposes compounds and keeps the original form. Example output:</p>
<div class="literalblock">
<div class="content">
<pre>가곡역 =&gt; 가곡역, 가곡, 역</pre>
</div>
</div>
</dd>
</dl>
</div>
</div>
</div>
</dd>
<dt class="hdlist1"><code>discard_punctuation</code></dt>
<dd>
<p>Whether punctuation should be discarded from the output. Defaults to <code>true</code>.</p>
</dd>
<dt class="hdlist1"><code>user_dictionary</code></dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>The Nori tokenizer uses the <a href="https://bitbucket.org/eunjeon/mecab-ko-dic">mecab-ko-dic dictionary</a> by default.
A <code>user_dictionary</code> with custom nouns (<code>NNG</code>) may be appended to the default dictionary.
The dictionary should have the following format:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-txt" data-lang="txt">&lt;token&gt; [&lt;token 1&gt; ... &lt;token n&gt;]</code></pre>
</div>
</div>
<div class="paragraph">
<p>The first token is mandatory and represents the custom noun that should be added in
the dictionary. For compound nouns the custom segmentation can be provided
after the first token (<code>[&lt;token 1&gt; &#8230;&#8203; &lt;token n&gt;]</code>). The segmentation of the
custom compound nouns is controlled by the <code>decompound_mode</code> setting.</p>
</div>
<div class="paragraph">
<p>As a demonstration of how the user dictionary can be used, save the following
dictionary to <code>$OPENSEARCH_HOME/config/userdict_ko.txt</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-txt" data-lang="txt">c++                 <b class="conum">(1)</b>
C샤프
세종
세종시 세종 시        <b class="conum">(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>A simple noun</p>
</li>
<li>
<p>A compound noun (<code>세종시</code>) followed by its decomposition: <code>세종</code> and <code>시</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Then create an analyzer as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "nori_user_dict": {
            "type": "nori_tokenizer",
            "decompound_mode": "mixed",
            "discard_punctuation": "false",
            "user_dictionary": "userdict_ko.txt"
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "nori_user_dict"
          }
        }
      }
    }
  }
}

GET nori_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "세종시"  <b class="conum">(1)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Sejong city</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The above <code>analyze</code> request returns the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "세종시",
    "start_offset" : 0,
    "end_offset" : 3,
    "type" : "word",
    "position" : 0,
    "positionLength" : 2    <b class="conum">(1)</b>
  }, {
    "token" : "세종",
    "start_offset" : 0,
    "end_offset" : 2,
    "type" : "word",
    "position" : 0
  }, {
    "token" : "시",
    "start_offset" : 2,
    "end_offset" : 3,
    "type" : "word",
    "position" : 1
   }]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>This is a compound token that spans two positions (<code>mixed</code> mode).</p>
</li>
</ol>
</div>
</div>
</div>
</dd>
<dt class="hdlist1"><code>user_dictionary_rules</code></dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>You can also inline the rules directly in the tokenizer definition using
the <code>user_dictionary_rules</code> option:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "nori_user_dict": {
            "type": "nori_tokenizer",
            "decompound_mode": "mixed",
            "user_dictionary_rules": ["c++", "C샤프", "세종", "세종시 세종 시"]
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "nori_user_dict"
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The <code>nori_tokenizer</code> sets a number of additional attributes per token that are used by token filters
to modify the stream.
You can view all these additional attributes with the following request:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">GET _analyze
{
  "tokenizer": "nori_tokenizer",
  "text": "뿌리가 깊은 나무는",   <b class="conum">(1)</b>
  "attributes" : ["posType", "leftPOS", "rightPOS", "morphemes", "reading"],
  "explain": true
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>A tree with deep roots</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Which responds with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "detail": {
    "custom_analyzer": true,
    "charfilters": [],
    "tokenizer": {
      "name": "nori_tokenizer",
      "tokens": [
        {
          "token": "뿌리",
          "start_offset": 0,
          "end_offset": 2,
          "type": "word",
          "position": 0,
          "leftPOS": "NNG(General Noun)",
          "morphemes": null,
          "posType": "MORPHEME",
          "reading": null,
          "rightPOS": "NNG(General Noun)"
        },
        {
          "token": "가",
          "start_offset": 2,
          "end_offset": 3,
          "type": "word",
          "position": 1,
          "leftPOS": "J(Ending Particle)",
          "morphemes": null,
          "posType": "MORPHEME",
          "reading": null,
          "rightPOS": "J(Ending Particle)"
        },
        {
          "token": "깊",
          "start_offset": 4,
          "end_offset": 5,
          "type": "word",
          "position": 2,
          "leftPOS": "VA(Adjective)",
          "morphemes": null,
          "posType": "MORPHEME",
          "reading": null,
          "rightPOS": "VA(Adjective)"
        },
        {
          "token": "은",
          "start_offset": 5,
          "end_offset": 6,
          "type": "word",
          "position": 3,
          "leftPOS": "E(Verbal endings)",
          "morphemes": null,
          "posType": "MORPHEME",
          "reading": null,
          "rightPOS": "E(Verbal endings)"
        },
        {
          "token": "나무",
          "start_offset": 7,
          "end_offset": 9,
          "type": "word",
          "position": 4,
          "leftPOS": "NNG(General Noun)",
          "morphemes": null,
          "posType": "MORPHEME",
          "reading": null,
          "rightPOS": "NNG(General Noun)"
        },
        {
          "token": "는",
          "start_offset": 9,
          "end_offset": 10,
          "type": "word",
          "position": 5,
          "leftPOS": "J(Ending Particle)",
          "morphemes": null,
          "posType": "MORPHEME",
          "reading": null,
          "rightPOS": "J(Ending Particle)"
        }
      ]
    },
    "tokenfilters": []
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-nori-speech"><code>nori_part_of_speech</code> token filter</h4>
<div class="paragraph">
<p>The <code>nori_part_of_speech</code> token filter removes tokens that match a set of
part-of-speech tags. The list of supported tags and their meanings can be found here:
<a href="https://lucene.apache.org/core/8_7_0/core/../analyzers-nori/org/apache/lucene/analysis/ko/POS.Tag.html">Part of speech tags</a></p>
</div>
<div class="paragraph">
<p>It accepts the following setting:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>stoptags</code></dt>
<dd>
<p>An array of part-of-speech tags that should be removed.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>and defaults to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"stoptags": [
    "E",
    "IC",
    "J",
    "MAG", "MAJ", "MM",
    "SP", "SSC", "SSO", "SC", "SE",
    "XPN", "XSA", "XSN", "XSV",
    "UNA", "NA", "VSV"
]</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "nori_tokenizer",
            "filter": [
              "my_posfilter"
            ]
          }
        },
        "filter": {
          "my_posfilter": {
            "type": "nori_part_of_speech",
            "stoptags": [
              "NR"   <b class="conum">(1)</b>
            ]
          }
        }
      }
    }
  }
}

GET nori_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "여섯 용이"  <b class="conum">(2)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Korean numerals should be removed (<code>NR</code>)</p>
</li>
<li>
<p>Six dragons</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Which responds with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "용",
    "start_offset" : 3,
    "end_offset" : 4,
    "type" : "word",
    "position" : 1
  }, {
    "token" : "이",
    "start_offset" : 4,
    "end_offset" : 5,
    "type" : "word",
    "position" : 2
  } ]
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-nori-readingform"><code>nori_readingform</code> token filter</h4>
<div class="paragraph">
<p>The <code>nori_readingform</code> token filter rewrites tokens written in Hanja to their Hangul form.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "nori_tokenizer",
            "filter": [ "nori_readingform" ]
          }
        }
      }
    }
  }
}

GET nori_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "鄕歌"      <b class="conum">(1)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>A token written in Hanja: Hyangga</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Which responds with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [ {
    "token" : "향가",     <b class="conum">(1)</b>
    "start_offset" : 0,
    "end_offset" : 2,
    "type" : "word",
    "position" : 0
  }]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>The Hanja form is replaced by the Hangul translation.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="analysis-nori-number"><code>nori_number</code> token filter</h4>
<div class="paragraph">
<p>The <code>nori_number</code> token filter normalizes Korean numbers
to regular Arabic decimal numbers in half-width characters.</p>
</div>
<div class="paragraph">
<p>Korean numbers are often written using a combination of Hangul and Arabic numbers with various kinds punctuation.
For example, ３．２천 means 3200.
This filter does this kind of normalization and allows a search for 3200 to match ３．２천 in text,
but can also be used to make range facets based on the normalized numbers and so on.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>Notice that this analyzer uses a token composition scheme and relies on punctuation tokens
being found in the token stream.
Please make sure your <code>nori_tokenizer</code> has <code>discard_punctuation</code> set to false.
In case punctuation characters, such as U+FF0E(．), is removed from the token stream,
this filter would find input tokens ３ and ２천 and give outputs 3 and 2000 instead of 3200,
which is likely not the intended result.</p>
</div>
<div class="paragraph">
<p>If you want to remove punctuation characters from your index that are not part of normalized numbers,
add a <code>stop</code> token filter with the punctuation you wish to remove after <code>nori_number</code> in your analyzer chain.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Below are some examples of normalizations this filter supports.
The input is untokenized text and the result is the single term attribute emitted for the input.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>영영칠 &#8594; 7</p>
</li>
<li>
<p>일영영영 &#8594; 1000</p>
</li>
<li>
<p>삼천2백2십삼 &#8594; 3223</p>
</li>
<li>
<p>조육백만오천일 &#8594; 1000006005001</p>
</li>
<li>
<p>３.２천 &#8594;  3200</p>
</li>
<li>
<p>１.２만３４５.６７ &#8594; 12345.67</p>
</li>
<li>
<p>4,647.100 &#8594; 4647.1</p>
</li>
<li>
<p>15,7 &#8594; 157 (be aware of this weakness)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT nori_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "tokenizer_discard_puncuation_false",
            "filter": [
              "part_of_speech_stop_sp", "nori_number"
            ]
          }
        },
        "tokenizer": {
          "tokenizer_discard_puncuation_false": {
            "type": "nori_tokenizer",
            "discard_punctuation": "false"
          }
        },
        "filter": {
            "part_of_speech_stop_sp": {
                "type": "nori_part_of_speech",
                "stoptags": ["SP"]
            }
        }
      }
    }
  }
}

GET nori_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "십만이천오백과 ３.２천"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which results in:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [{
    "token" : "102500",
    "start_offset" : 0,
    "end_offset" : 6,
    "type" : "word",
    "position" : 0
  }, {
    "token" : "과",
    "start_offset" : 6,
    "end_offset" : 7,
    "type" : "word",
    "position" : 1
  }, {
    "token" : "3200",
    "start_offset" : 8,
    "end_offset" : 12,
    "type" : "word",
    "position" : 2
  }]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="analysis-phonetic">Phonetic Analysis Plugin</h3>
<div class="paragraph">
<p>The Phonetic Analysis plugin provides token filters which convert tokens to
their phonetic representation using Soundex, Metaphone, and a variety of other
algorithms.</p>
</div>
<h4 id="analysis-phonetic-install" class="discrete">Installation</h4>
<div class="paragraph">
<p>This plugin can be installed using the plugin manager:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin install analysis-phonetic</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.</p>
</div>
<div class="paragraph">
<p>You can download this plugin for <a href="plugin-management.html#plugin-management-custom-url">offline
install</a> from <a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-phonetic/analysis-phonetic-1.0.0.zip" class="bare">https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-phonetic/analysis-phonetic-1.0.0.zip</a>. To verify
the <code>.zip</code> file, use the
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-phonetic/analysis-phonetic-1.0.0.zip.sha512">SHA hash</a> or
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-phonetic/analysis-phonetic-1.0.0.zip.asc">ASC key</a>.</p>
</div>
<h4 id="analysis-phonetic-remove" class="discrete">Removal</h4>
<div class="paragraph">
<p>The plugin can be removed with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin remove analysis-phonetic</code></pre>
</div>
</div>
<div class="paragraph">
<p>The node must be stopped before removing the plugin.</p>
</div>
<div class="sect3">
<h4 id="analysis-phonetic-token-filter"><code>phonetic</code> token filter</h4>
<div class="paragraph">
<p>The <code>phonetic</code> token filter takes the following settings:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>encoder</code></dt>
<dd>
<p>Which phonetic encoder to use.  Accepts <code>metaphone</code> (default),
<code>double_metaphone</code>, <code>soundex</code>, <code>refined_soundex</code>, <code>caverphone1</code>,
<code>caverphone2</code>, <code>cologne</code>, <code>nysiis</code>, <code>koelnerphonetik</code>, <code>haasephonetik</code>,
<code>beider_morse</code>, <code>daitch_mokotoff</code>.</p>
</dd>
<dt class="hdlist1"><code>replace</code></dt>
<dd>
<p>Whether or not the original token should be replaced by the phonetic
token. Accepts <code>true</code> (default) and <code>false</code>.  Not supported by
<code>beider_morse</code> encoding.</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT phonetic_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "standard",
            "filter": [
              "lowercase",
              "my_metaphone"
            ]
          }
        },
        "filter": {
          "my_metaphone": {
            "type": "phonetic",
            "encoder": "metaphone",
            "replace": false
          }
        }
      }
    }
  }
}

GET phonetic_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "Joe Bloggs" <b class="conum">(1)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Returns: <code>J</code>, <code>joe</code>, <code>BLKS</code>, <code>bloggs</code></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>It is important to note that <code>"replace": false</code> can lead to unexpected behavior since
the original and the phonetically analyzed version are both kept at the same token position.
Some queries handle these stacked tokens in special ways. For example, the fuzzy <code>match</code>
query does not apply <a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/common-options.html#fuzziness">fuzziness</a> to stacked synonym tokens.
This can lead to issues that are difficult to diagnose and reason about. For this reason, it
is often beneficial to use separate fields for analysis with and without phonetic filtering.
That way searches can be run against both fields with differing boosts and trade-offs (e.g.
only run a fuzzy <code>match</code> query on the original text field, but not on the phonetic version).</p>
</div>
<h5 id="_double_metaphone_settings" class="discrete">Double metaphone settings</h5>
<div class="paragraph">
<p>If the <code>double_metaphone</code> encoder is used, then this additional setting is
supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>max_code_len</code></dt>
<dd>
<p>The maximum length of the emitted metaphone token.  Defaults to <code>4</code>.</p>
</dd>
</dl>
</div>
<h5 id="_beider_morse_settings" class="discrete">Beider Morse settings</h5>
<div class="paragraph">
<p>If the <code>beider_morse</code> encoder is used, then these additional settings are
supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>rule_type</code></dt>
<dd>
<p>Whether matching should be <code>exact</code> or <code>approx</code> (default).</p>
</dd>
<dt class="hdlist1"><code>name_type</code></dt>
<dd>
<p>Whether names are <code>ashkenazi</code>, <code>sephardic</code>, or <code>generic</code> (default).</p>
</dd>
<dt class="hdlist1"><code>languageset</code></dt>
<dd>
<p>An array of languages to check. If not specified, then the language will
be guessed. Accepts: <code>any</code>, <code>common</code>, <code>cyrillic</code>, <code>english</code>, <code>french</code>,
<code>german</code>, <code>hebrew</code>, <code>hungarian</code>, <code>polish</code>, <code>romanian</code>, <code>russian</code>,
<code>spanish</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="analysis-smartcn">Smart Chinese Analysis Plugin</h3>
<div class="paragraph">
<p>The Smart Chinese Analysis plugin integrates Lucene&#8217;s Smart Chinese analysis
module into opensearch.</p>
</div>
<div class="paragraph">
<p>It provides an analyzer for Chinese or mixed Chinese-English text. This
analyzer uses probabilistic knowledge to find the optimal word segmentation
for Simplified Chinese text. The text is first broken into sentences, then
each sentence is segmented into words.</p>
</div>
<h4 id="analysis-smartcn-install" class="discrete">Installation</h4>
<div class="paragraph">
<p>This plugin can be installed using the plugin manager:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin install analysis-smartcn</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.</p>
</div>
<div class="paragraph">
<p>You can download this plugin for <a href="plugin-management.html#plugin-management-custom-url">offline
install</a> from <a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-smartcn/analysis-smartcn-1.0.0.zip" class="bare">https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-smartcn/analysis-smartcn-1.0.0.zip</a>. To verify
the <code>.zip</code> file, use the
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-smartcn/analysis-smartcn-1.0.0.zip.sha512">SHA hash</a> or
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-smartcn/analysis-smartcn-1.0.0.zip.asc">ASC key</a>.</p>
</div>
<h4 id="analysis-smartcn-remove" class="discrete">Removal</h4>
<div class="paragraph">
<p>The plugin can be removed with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin remove analysis-smartcn</code></pre>
</div>
</div>
<div class="paragraph">
<p>The node must be stopped before removing the plugin.</p>
</div>
<h4 id="analysis-smartcn-tokenizer" class="discrete"><code>smartcn</code> tokenizer and token filter</h4>
<div class="paragraph">
<p>The plugin provides the <code>smartcn</code> analyzer, <code>smartcn_tokenizer</code> tokenizer, and
<code>smartcn_stop</code> token filter which are not configurable.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The <code>smartcn_word</code> token filter and <code>smartcn_sentence</code> have been deprecated.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_reimplementing_and_extending_the_analyzers">Reimplementing and extending the analyzers</h4>
<div class="paragraph">
<p>The <code>smartcn</code> analyzer could be reimplemented as a <code>custom</code> analyzer that can
then be extended and configured as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT smartcn_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_smartcn": {
          "tokenizer":  "smartcn_tokenizer",
          "filter": [
            "porter_stem",
            "smartcn_stop"
          ]
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-smartcn_stop"><code>smartcn_stop</code> token filter</h4>
<div class="paragraph">
<p>The <code>smartcn_stop</code> token filter filters out stopwords defined by <code>smartcn</code>
analyzer (<code><em>smartcn</em></code>), and any other custom stopwords specified by the user.
This filter only supports the predefined <code><em>smartcn</em></code> stopwords list.
If you want to use a different predefined list, then use the
<a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-stop-tokenfilter.html"><code>stop</code> token filter</a> instead.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT smartcn_example
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "smartcn_with_stop": {
            "tokenizer": "smartcn_tokenizer",
            "filter": [
              "porter_stem",
              "my_smartcn_stop"
            ]
          }
        },
        "filter": {
          "my_smartcn_stop": {
            "type": "smartcn_stop",
            "stopwords": [
              "_smartcn_",
              "project",
              "的"
            ]
          }
        }
      }
    }
  }
}

GET smartcn_example/_analyze
{
  "analyzer": "smartcn_with_stop",
  "text": "哈喽，我们是 OpenSearch Project（OpenSearch 和 OpenSearch Dashboards）的开发者。从股票行情到 Twitter 消息流，从 Apache 日志到 WordPress 博文，我们可以帮助人们体验搜索的强大力量，帮助他们以截然不同的方式探索和分析数据"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above request returns:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens": [
    {
      "token": "哈",
      "start_offset": 0,
      "end_offset": 1,
      "type": "word",
      "position": 0
    },
    {
      "token": "喽",
      "start_offset": 1,
      "end_offset": 2,
      "type": "word",
      "position": 1
    },
    {
      "token": "我们",
      "start_offset": 3,
      "end_offset": 5,
      "type": "word",
      "position": 3
    },
    {
      "token": "是",
      "start_offset": 5,
      "end_offset": 6,
      "type": "word",
      "position": 4
    },
    {
      "token": "opensearch",
      "start_offset": 7,
      "end_offset": 17,
      "type": "word",
      "position": 5
    },
    {
      "token": "opensearch",
      "start_offset": 26,
      "end_offset": 36,
      "type": "word",
      "position": 8
    },
    {
      "token": "和",
      "start_offset": 37,
      "end_offset": 38,
      "type": "word",
      "position": 9
    },
    {
      "token": "opensearch",
      "start_offset": 39,
      "end_offset": 49,
      "type": "word",
      "position": 10
    },
    {
      "token": "dashboard",
      "start_offset": 50,
      "end_offset": 60,
      "type": "word",
      "position": 11
    },
    {
      "token": "开发",
      "start_offset": 62,
      "end_offset": 64,
      "type": "word",
      "position": 14
    },
    {
      "token": "者",
      "start_offset": 64,
      "end_offset": 65,
      "type": "word",
      "position": 15
    },
    {
      "token": "从",
      "start_offset": 66,
      "end_offset": 67,
      "type": "word",
      "position": 17
    },
    {
      "token": "股票",
      "start_offset": 67,
      "end_offset": 69,
      "type": "word",
      "position": 18
    },
    {
      "token": "行情",
      "start_offset": 69,
      "end_offset": 71,
      "type": "word",
      "position": 19
    },
    {
      "token": "到",
      "start_offset": 71,
      "end_offset": 72,
      "type": "word",
      "position": 20
    },
    {
      "token": "twitter",
      "start_offset": 73,
      "end_offset": 80,
      "type": "word",
      "position": 21
    },
    {
      "token": "消息",
      "start_offset": 81,
      "end_offset": 83,
      "type": "word",
      "position": 22
    },
    {
      "token": "流",
      "start_offset": 83,
      "end_offset": 84,
      "type": "word",
      "position": 23
    },
    {
      "token": "从",
      "start_offset": 85,
      "end_offset": 86,
      "type": "word",
      "position": 25
    },
    {
      "token": "apach",
      "start_offset": 87,
      "end_offset": 93,
      "type": "word",
      "position": 26
    },
    {
      "token": "日志",
      "start_offset": 94,
      "end_offset": 96,
      "type": "word",
      "position": 27
    },
    {
      "token": "到",
      "start_offset": 96,
      "end_offset": 97,
      "type": "word",
      "position": 28
    },
    {
      "token": "wordpress",
      "start_offset": 98,
      "end_offset": 107,
      "type": "word",
      "position": 29
    },
    {
      "token": "博",
      "start_offset": 108,
      "end_offset": 109,
      "type": "word",
      "position": 30
    },
    {
      "token": "文",
      "start_offset": 109,
      "end_offset": 110,
      "type": "word",
      "position": 31
    },
    {
      "token": "我们",
      "start_offset": 111,
      "end_offset": 113,
      "type": "word",
      "position": 33
    },
    {
      "token": "可以",
      "start_offset": 113,
      "end_offset": 115,
      "type": "word",
      "position": 34
    },
    {
      "token": "帮助",
      "start_offset": 115,
      "end_offset": 117,
      "type": "word",
      "position": 35
    },
    {
      "token": "人们",
      "start_offset": 117,
      "end_offset": 119,
      "type": "word",
      "position": 36
    },
    {
      "token": "体验",
      "start_offset": 119,
      "end_offset": 121,
      "type": "word",
      "position": 37
    },
    {
      "token": "搜索",
      "start_offset": 121,
      "end_offset": 123,
      "type": "word",
      "position": 38
    },
    {
      "token": "强大",
      "start_offset": 124,
      "end_offset": 126,
      "type": "word",
      "position": 40
    },
    {
      "token": "力量",
      "start_offset": 126,
      "end_offset": 128,
      "type": "word",
      "position": 41
    },
    {
      "token": "帮助",
      "start_offset": 129,
      "end_offset": 131,
      "type": "word",
      "position": 43
    },
    {
      "token": "他们",
      "start_offset": 131,
      "end_offset": 133,
      "type": "word",
      "position": 44
    },
    {
      "token": "以",
      "start_offset": 133,
      "end_offset": 134,
      "type": "word",
      "position": 45
    },
    {
      "token": "截然不同",
      "start_offset": 134,
      "end_offset": 138,
      "type": "word",
      "position": 46
    },
    {
      "token": "方式",
      "start_offset": 139,
      "end_offset": 141,
      "type": "word",
      "position": 48
    },
    {
      "token": "探索",
      "start_offset": 141,
      "end_offset": 143,
      "type": "word",
      "position": 49
    },
    {
      "token": "和",
      "start_offset": 143,
      "end_offset": 144,
      "type": "word",
      "position": 50
    },
    {
      "token": "分析",
      "start_offset": 144,
      "end_offset": 146,
      "type": "word",
      "position": 51
    },
    {
      "token": "数据",
      "start_offset": 146,
      "end_offset": 148,
      "type": "word",
      "position": 52
    }
  ]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="analysis-stempel">Stempel Polish Analysis Plugin</h3>
<div class="paragraph">
<p>The Stempel Analysis plugin integrates Lucene&#8217;s Stempel analysis
module for Polish into opensearch.</p>
</div>
<h4 id="analysis-stempel-install" class="discrete">Installation</h4>
<div class="paragraph">
<p>This plugin can be installed using the plugin manager:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin install analysis-stempel</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.</p>
</div>
<div class="paragraph">
<p>You can download this plugin for <a href="plugin-management.html#plugin-management-custom-url">offline
install</a> from <a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-stempel/analysis-stempel-1.0.0.zip" class="bare">https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-stempel/analysis-stempel-1.0.0.zip</a>. To verify
the <code>.zip</code> file, use the
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-stempel/analysis-stempel-1.0.0.zip.sha512">SHA hash</a> or
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-stempel/analysis-stempel-1.0.0.zip.asc">ASC key</a>.</p>
</div>
<h4 id="analysis-stempel-remove" class="discrete">Removal</h4>
<div class="paragraph">
<p>The plugin can be removed with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin remove analysis-stempel</code></pre>
</div>
</div>
<div class="paragraph">
<p>The node must be stopped before removing the plugin.</p>
</div>
<h4 id="analysis-stempel-tokenizer" class="discrete"><code>stempel</code> tokenizer and token filters</h4>
<div class="paragraph">
<p>The plugin provides the <code>polish</code> analyzer and the <code>polish_stem</code> and <code>polish_stop</code> token filters,
which are not configurable.</p>
</div>
<div class="sect3">
<h4 id="_reimplementing_and_extending_the_analyzers_2">Reimplementing and extending the analyzers</h4>
<div class="paragraph">
<p>The <code>polish</code> analyzer could be reimplemented as a <code>custom</code> analyzer that can
then be extended and configured differently as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT /stempel_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_stempel": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "polish_stop",
            "polish_stem"
          ]
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="analysis-polish-stop"><code>polish_stop</code> token filter</h4>
<div class="paragraph">
<p>The <code>polish_stop</code> token filter filters out Polish stopwords (<code><em>polish</em></code>), and
any other custom stopwords specified by the user. This filter only supports
the predefined <code><em>polish</em></code> stopwords list.  If you want to use a different
predefined list, then use the
<a href="https://www.opensearch.org/guide/en/opensearch/reference/{branch}/analysis-stop-tokenfilter.html"><code>stop</code> token filter</a> instead.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PUT /polish_stop_example
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "analyzer_with_stop": {
            "tokenizer": "standard",
            "filter": [
              "lowercase",
              "polish_stop"
            ]
          }
        },
        "filter": {
          "polish_stop": {
            "type": "polish_stop",
            "stopwords": [
              "_polish_",
              "jeść"
            ]
          }
        }
      }
    }
  }
}

GET polish_stop_example/_analyze
{
  "analyzer": "analyzer_with_stop",
  "text": "Gdzie kucharek sześć, tam nie ma co jeść."
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above request returns:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console-result" data-lang="console-result">{
  "tokens" : [
    {
      "token" : "kucharek",
      "start_offset" : 6,
      "end_offset" : 14,
      "type" : "&lt;ALPHANUM&gt;",
      "position" : 1
    },
    {
      "token" : "sześć",
      "start_offset" : 15,
      "end_offset" : 20,
      "type" : "&lt;ALPHANUM&gt;",
      "position" : 2
    }
  ]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="analysis-ukrainian">Ukrainian Analysis Plugin</h3>
<div class="paragraph">
<p>The Ukrainian Analysis plugin integrates Lucene&#8217;s UkrainianMorfologikAnalyzer into opensearch.</p>
</div>
<div class="paragraph">
<p>It provides stemming for Ukrainian using the <a href="https://github.com/morfologik/morfologik-stemming">Morfologik project</a>.</p>
</div>
<h4 id="analysis-ukrainian-install" class="discrete">Installation</h4>
<div class="paragraph">
<p>This plugin can be installed using the plugin manager:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin install analysis-ukrainian</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plugin must be installed on every node in the cluster, and each node must
be restarted after installation.</p>
</div>
<div class="paragraph">
<p>You can download this plugin for <a href="plugin-management.html#plugin-management-custom-url">offline
install</a> from <a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-ukrainian/analysis-ukrainian-1.0.0.zip" class="bare">https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-ukrainian/analysis-ukrainian-1.0.0.zip</a>. To verify
the <code>.zip</code> file, use the
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-ukrainian/analysis-ukrainian-1.0.0.zip.sha512">SHA hash</a> or
<a href="https://artifacts.opensearch.org/downloads/opensearch-plugins/analysis-ukrainian/analysis-ukrainian-1.0.0.zip.asc">ASC key</a>.</p>
</div>
<h4 id="analysis-ukrainian-remove" class="discrete">Removal</h4>
<div class="paragraph">
<p>The plugin can be removed with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sh" data-lang="sh">sudo bin/opensearch-plugin remove analysis-ukrainian</code></pre>
</div>
</div>
<div class="paragraph">
<p>The node must be stopped before removing the plugin.</p>
</div>
<h4 id="analysis-ukrainian-analyzer" class="discrete"><code>ukrainian</code> analyzer</h4>
<div class="paragraph">
<p>The plugin provides the <code>ukrainian</code> analyzer.</p>
</div>
</div>
</div>
</div>
<div class="paragraph nav-footer">
<p>← Previous: <a href="plugin-management.html">Plugin Management</a> | ↑ Up: <a href="index.html">OpenSearch Plugins and Integrations</a> | Next: <a href="discovery.html">Discovery Plugins</a> →</p>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2021-04-05 12:06:59 -0700
</div>
</div>
</body>
</html>